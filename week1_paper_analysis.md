### Paper 1

| Field | Entry |
| --- | --- |
| **Title and citation** | Ye, F., Wang, R., Tang, S., Duan, S., & Xu, C. (2024). *Federated Learning-Enabled Cooperative Localization in Multi-agent System*. International Journal of Wireless Information Networks, 31, 61–72. |
| **Problem addressed** | Cooperative localization in multi-agent systems is crucial for applications such as emergency rescue and navigation. Traditional approaches require data sharing, which raises privacy concerns and can be inefficient under heterogeneous data conditions. The study explores whether federated learning (FL) can enable accurate, privacy-preserving cooperative localization. |
| **Methodologies used** | - Developed a **Gaussian Process State-Space Model (GPSSM)** to capture agent dynamics and manage noise.<br> - Applied **Federated Learning (FedAvg + ADMM)** for multi-agent model aggregation, reducing communication overhead while maintaining privacy.<br> - Conducted simulations using Turtlebot3 agents in a Gazebo environment, combining UWB and IMU sensor data.<br> - Evaluated performance under both i.i.d. and non-i.i.d. data distributions. |
| **Main findings / contributions** | - The FL model maintained comparable localization accuracy to centralized methods, with root mean square error (RMSE) values below 0.1 m in most cases.<br> - Demonstrated strong **robustness** and **generalization** in heterogeneous (non-i.i.d.) scenarios.<br> - The federated approach prevented privacy leakage since raw data stayed local.<br> - Showed excellent **transfer learning performance**, enabling rapid adaptation to novel environments. |
| **Limitations / open questions** | - Slight performance gap compared to centralized models (federated RMSE ~0.07–0.09 m vs centralized ~0.017 m).<br> - Communication efficiency still limited by model parameter size, especially for scaling to larger networks.<br> - Evaluation was simulation-based; real-world deployment with noisy, large-scale data remains untested.<br> - Future work suggested improving training data quality and diversifying agent motion patterns. |
| **Relevance to chosen topic** | Directly relevant as it applies **federated learning to multi-agent systems** while addressing **privacy and scalability issues** in localization. This supports broader applications in **smart transportation, robotics, and intelligent systems**, showing how FL can balance accuracy, robustness, and privacy. |


### Paper 2

| Field | Entry |
| --- | --- |
| **Title and citation** | Wang, Z., Wu, F., Yu, F., Zhou, Y., Hu, J., & Min, G. (2024). *Federated Continual Learning for Edge-AI: A Comprehensive Survey*. ACM Computing Surveys, 1(1), 35 pp.|
| **Problem addressed** | Traditional federated learning (FL) assumes static data distributions, but in real-world **Edge-AI systems**, data and tasks evolve over time. This dynamic setting causes **catastrophic forgetting** and performance degradation. The paper surveys the emerging field of **Federated Continual Learning (FCL)**, which integrates continual learning (CL) with FL to enable adaptive, privacy-preserving, and resilient AI at the edge. |
| **Methodologies used** | -  |
| **Main findings / contributions** | -  |
| **Limitations / open questions** | - |
| **Relevance to chosen topic** |  |


#Literature review

### Paper 3

| Field | Entry |
| --- | --- |
| **Title and citation** | Chellapandi, V. P., Yuan, L., Żak, S. H., & Wang, Z. (2023). *A Survey of Federated Learning for Connected and Automated Vehicles*. IEEE 26th International Conference on Intelligent Transportation Systems (ITSC), Bilbao, Spain. |
| **Problem addressed** | Connected and Automated Vehicles (CAVs) generate massive, sensitive data from sensors, cameras, and V2X communications. Centralized training raises privacy risks, scalability issues, and high communication costs. The paper surveys how **federated learning (FL)** can address these challenges while improving perception, prediction, and decision-making in CAV systems. |
| **Methodologies used** | - Reviews **data modalities** used in CAVs (RGB images, LiDAR, GNSS, IMU, vehicle status data).<br> - Discusses **privacy-preserving techniques**: homomorphic encryption, secure multi-party computation, differential privacy, blockchain.<br> - Examines **FL algorithms**: FedAvg, FedProx, FedAdam, Dynamic FL, Federated Distillation, clustered FL.<br> - Surveys applications of FL4CAV in **steering angle prediction, trajectory prediction, object detection, driver monitoring, motion control**. |
| **Main findings / contributions** | - Provides the first **comprehensive overview of FL applications in CAVs**, covering perception, planning, and control tasks.<br> - Summarizes datasets and models (e.g., YOLO, ResNet, CNN, RNN, BiSeNet, RL) used in FL4CAV studies.<br> - Highlights advantages of FL: **privacy preservation, reduced communication overhead, generalization across diverse driving environments**.<br> - Identifies that FL can achieve performance close to centralized methods while respecting privacy and communication limits. |
| **Limitations / open questions** | - **Resource limitations**: communication overhead, scalability to massive fleets, lack of high-fidelity simulators.<br> - **Privacy/security**: vulnerability to malicious updates and server attacks despite secure aggregation.<br> - **Methodological gaps**: client drift, catastrophic forgetting, lack of fairness/incentive mechanisms, robustness in heterogeneous conditions.<br> - **Evaluation issues**: shortage of real-world datasets under diverse weather/traffic conditions, inadequate diagnostic tools. |
| **Relevance to chosen topic** | As a **survey paper**, it maps the entire FL4CAV research landscape, offering taxonomies of algorithms, applications, and privacy-preserving methods. It is highly relevant for identifying gaps in **federated learning for intelligent transportation**, particularly regarding privacy, scalability, and robustness in real-world deployment. |

### Paper 4

| Field | Entry |
| --- | --- |
| **Title and citation** | Zhao, Y., Yang, Y., Yu, H., Kumari, S., Amoon, M., Kumar, S., & Ren, Y. (2025). *Federated Learning Intersection Vehicle Trajectory Prediction Scheme Within Digital Twin*. IEEE Transactions on Intelligent Transportation Systems. 
| **Problem addressed** | Digital Twin (DT) systems enable real-time simulation of urban traffic but face privacy and security issues since sensitive vehicle trajectory data cannot be centralized. Traditional centralized approaches limit model accuracy and robustness. The paper explores whether **federated learning (FL)** can enable accurate, privacy-preserving trajectory prediction at complex intersections within DT frameworks. |
| **Methodologies used** | - Proposed **FedSTAST model** (Federated Spatio-Temporal-Semantic Attention-based Trajectory).<br> - Built on an encoder–decoder with multi-layer feature fusion (temporal, spatial, semantic).<br> - Integrated **edge computing** for local training and parameter sharing.<br> - Designed client-side (encrypted sample alignment, FedProx optimization) and center-side (clustering + aggregation) algorithms.<br> - Conducted simulations using the **Argoverse 1 motion prediction dataset** for training and evaluation. |
| **Main findings / contributions** | - FedSTAST significantly improved **trajectory prediction accuracy** compared to baseline models (e.g., CV, LSTM, NN).<br> - Achieved **comparable results to centralized training** while preserving privacy.<br> - Reduced communication costs through edge-based training and semantic-aware federated architecture.<br> - Outperformed other FL baselines (FedAvg, FedProx, FedBCD) in terms of ADE, FDE, and robustness under multimodal conditions.<br> - Showed scalability through clustering to manage large numbers of federated clients. |
| **Limitations / open questions** | - Slight performance gap remains vs. ideal centralized models.<br> - Computational and communication efficiency could still be optimized, especially under large-scale deployments.<br> - Experiments conducted on **simulated DT environments**; real-world large-scale validation is missing.<br> - Generalization across diverse geographic and traffic conditions still needs improvement.<br> - Future work: improve model robustness, broaden semantic feature integration, and adapt FedSTAST to heterogeneous inputs. |
| **Relevance to chosen topic** | Directly relevant as it focuses on **FL for trajectory prediction in intelligent transportation systems**, specifically within **Digital Twin environments**. It demonstrates how FL can balance privacy, accuracy, and efficiency, offering practical insights for smart city and autonomous driving applications. |

### Paper 5

| Field | Entry |
| --- | --- |
| **Title and citation** | Hamedi, P., Razavi-Far, R., & Hallaji, E. (2025). *Federated Continual Learning: Concepts, Challenges, and Solutions*. Neurocomputing, 651, 130844. |
| **Problem addressed** | In real-world distributed systems, data is **non-stationary** and continuously generated, but traditional federated learning (FL) assumes static data distributions. Continual learning (CL) addresses non-stationary data but struggles with privacy and distributed settings. This survey paper explores how **Federated Continual Learning (FCL)** integrates FL and CL to enable **privacy-preserving, adaptive, and scalable learning** over dynamic data streams. |
| **Methodologies used** | - Provides a **structured taxonomy** of FCL challenges: heterogeneity (statistical, conceptual, system), catastrophic forgetting, concept drift (virtual, real, hybrid), communication overhead, model stability, privacy preservation, and resource constraints.<br> - Reviews **existing solutions**: generative replay, knowledge distillation, domain adaptation, clustering, personalization, multi-task learning, secure aggregation, differential privacy, homomorphic encryption.<br> - Analyzes **global vs local issues** (e.g., global catastrophic forgetting vs local forgetting).<br> - Summarizes datasets, benchmarks, and performance metrics used in FCL research. |
| **Main findings / contributions** | - First survey to **systematically connect FL and CL challenges** and show how they interact in FCL.<br> - Identifies **taxonomy of heterogeneity**: non-IID data, imbalanced distributions, inconsistent labeling, client-specific features, and resource/system heterogeneity.<br> - Clarifies **concept drift categories** (virtual, real, hybrid) and maps them to FCL scenarios.<br> - Presents taxonomy of **catastrophic forgetting solutions** (proxy models, prototypical learning, optimization-based approaches, knowledge distillation, gradient modifications).<br> - Reviews **privacy-preserving FCL approaches**, emphasizing secure aggregation, SMC, DP, and HE.<br> - Outlines **open challenges** like stability–plasticity dilemma, fairness, dynamic client participation, large-scale deployment, and benchmarking gaps. |
| **Limitations / open questions** | - Lack of standardized **benchmarks and evaluation metrics** for FCL methods.<br> - Most methods tested on small datasets (CIFAR, MNIST, GTSRB), not large-scale real-world systems.<br> - Privacy-preserving techniques (e.g., DP, HE) often degrade performance and increase resource cost.<br> - Open problem: balancing **plasticity (adaptation to new tasks)** with **stability (retention of old knowledge)**.<br> - Limited real-world deployment studies; need for cross-domain validation (healthcare, IoT, smart transportation). |
| **Relevance to chosen topic** | This survey is highly relevant as it provides a **conceptual foundation and taxonomy** for FCL research. It complements other survey papers in your review by mapping **open problems and solutions** that are directly applicable to intelligent transportation, robotics, and edge-based AI systems using federated learning. |

### Paper 6

| Field | Entry |
| --- | --- |
| **Title and citation** | Guo, X., Zhang, Q., Jiang, J., Peng, M., Zhu, M., & Yang, H. (2024). *Towards Explainable Traffic Flow Prediction with Large Language Models*. arXiv preprint arXiv:2404.02937. |
| **Problem addressed** | Deep learning has advanced traffic forecasting but suffers from **black-box opacity**, requiring complex architectures that limit interpretability and accountability. Achieving models that are both **accurate and explainable** for traffic flow prediction remains an open challenge. |
| **Methodologies used** | - Proposed **xTP-LLM**, a traffic prediction framework based on Large Language Models (LLMs).<br> - Converted multi-modal traffic data (historical flows, weather, PoIs, holidays, spatial attributes) into **text-based prompts**.<br> - Incorporated **Chain-of-Thought (CoT) prompting** and domain-specific system prompts to guide reasoning.<br> - Fine-tuned **Llama2-7B-chat** with **LoRA** for efficient adaptation.<br> - Created **CATraffic dataset** (subset of LargeST + enriched with external factors).<br> - Compared against 9 baselines (LSTM, DCRNN, STGCN, GWNET, ASTGCN, AGCRN, STTN, STGODE, DSTAGNN). |
| **Main findings / contributions** | - **Accuracy**: xTP-LLM outperformed state-of-the-art baselines, improving MAE by 18–34% and MAPE by up to 34%.<br> - **Explainability**: Produced natural-language rationales for predictions, improving accountability in ITS.<br> - **Robustness**: Maintained stable MAE (21–23) across peak/off-peak, weekdays/weekends, and weather conditions.<br> - **Generalization**: Achieved strong zero-shot performance on unseen datasets (e.g., TaxiBJ), outperforming GPT-4 and Llama2-70B despite smaller scale.<br> - **Ablation**: Showed that combining CoT + domain knowledge prompts improved accuracy synergistically. |
| **Limitations / open questions** | - Still struggles with **fine-grained fluctuations** (e.g., sudden shifts between 14–18h).<br> - Computationally heavy: fine-tuning and inference with LLMs remain resource-intensive.<br> - Dataset limited to California regions; broader geographic validation required.<br> - Explainability depends on prompt quality; explanations sometimes verbose or inconsistent. |
| **Relevance to chosen topic** | Directly relevant as it pioneers the use of **LLMs for traffic prediction with explainability**. Complements FL-based ITS studies by showing how **foundation models + structured prompts** can improve interpretability, a critical gap in existing black-box deep learning approaches. |
